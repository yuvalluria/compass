{
  "metadata": {
    "source": "estimated_performance_interpolation",
    "description": "Estimated performance data for high-accuracy models without real benchmarks",
    "generated_at": "2025-12-31T11:08:02.902423",
    "total_configs": 70,
    "unique_models": 30,
    "estimation_method": "family_size_interpolation with hardware scaling",
    "confidence_level": 0.75,
    "disclaimer": "These are ESTIMATED values based on similar models. Real benchmarks may differ.",
    "models": [
      "DeepSeek V3.2 Exp (Reasoning)",
      "DeepSeek V3.1 Terminus (Reasoning)",
      "MiniMax-M2",
      "Magistral Medium 1.2",
      "Magistral Small 1.2",
      "Llama Nemotron Super 49B v1.5 (Reasoning)",
      "Solar Pro 2 (Reasoning)",
      "DeepSeek R1 Distill Llama 70B",
      "Gemma 3 27B Instruct",
      "Gemma 3 12B Instruct",
      "Llama 3.1 Instruct 405B",
      "Mistral Medium 3.1",
      "Mistral Small 3.2",
      "DeepSeek R1 0528 Qwen3 8B",
      "Qwen3 235B A22B (Thinking)",
      "Phi-4 Mini Instruct",
      "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
      "Llama 3.3 Nemotron Super 49B v1 (Reasoning)",
      "Solar Pro 2 (Non-reasoning)",
      "DeepSeek V3.2 Exp (Non-reasoning)",
      "Kimi K2 Thinking",
      "Ring-1T",
      "GLM-4.5 (Reasoning)",
      "Apriel-v1.5-15B-Thinker",
      "EXAONE 4.0 32B (Reasoning)",
      "MiniMax M1 80k",
      "Doubao Seed Code",
      "Seed-OSS-36B-Instruct",
      "Qwen3 32B (Reasoning)",
      "GLM-4.5-Air"
    ]
  },
  "benchmarks": [
    {
      "model_id": "deepseek/DeepSeek-V3.2-Exp-Reasoning",
      "model_name": "DeepSeek V3.2 Exp (Reasoning)",
      "hardware": "H200",
      "hardware_count": 8,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 145,
      "ttft_p90": 207,
      "ttft_p95": 249,
      "ttft_p99": 311,
      "itl_mean": 16,
      "itl_p90": 24,
      "itl_p95": 30,
      "itl_p99": 37,
      "e2e_mean": 9238,
      "e2e_p90": 12010,
      "e2e_p95": 14320,
      "e2e_p99": 17553,
      "tokens_per_second_mean": 295,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 670,
        "accuracy_score": 62.4,
        "hardware": "H200",
        "hardware_count": 8
      },
      "based_on": "DeepSeek R1 family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "deepseek/DeepSeek-V3.2-Exp-Reasoning",
      "model_name": "DeepSeek V3.2 Exp (Reasoning)",
      "hardware": "B200",
      "hardware_count": 8,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 125,
      "ttft_p90": 180,
      "ttft_p95": 216,
      "ttft_p99": 270,
      "itl_mean": 14,
      "itl_p90": 21,
      "itl_p95": 26,
      "itl_p99": 32,
      "e2e_mean": 8006,
      "e2e_p90": 10409,
      "e2e_p95": 12411,
      "e2e_p99": 15213,
      "tokens_per_second_mean": 338,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 670,
        "accuracy_score": 62.4,
        "hardware": "B200",
        "hardware_count": 8
      },
      "based_on": "DeepSeek R1 family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "deepseek/DeepSeek-V3.1-Terminus-Reasoning",
      "model_name": "DeepSeek V3.1 Terminus (Reasoning)",
      "hardware": "H200",
      "hardware_count": 8,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 147,
      "ttft_p90": 210,
      "ttft_p95": 252,
      "ttft_p99": 315,
      "itl_mean": 16,
      "itl_p90": 24,
      "itl_p95": 30,
      "itl_p99": 38,
      "e2e_mean": 9349,
      "e2e_p90": 12153,
      "e2e_p95": 14491,
      "e2e_p99": 17763,
      "tokens_per_second_mean": 295,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 670,
        "accuracy_score": 63.9,
        "hardware": "H200",
        "hardware_count": 8
      },
      "based_on": "DeepSeek R1 family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "deepseek/DeepSeek-V3.1-Terminus-Reasoning",
      "model_name": "DeepSeek V3.1 Terminus (Reasoning)",
      "hardware": "B200",
      "hardware_count": 8,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 127,
      "ttft_p90": 182,
      "ttft_p95": 218,
      "ttft_p99": 273,
      "itl_mean": 14,
      "itl_p90": 21,
      "itl_p95": 26,
      "itl_p99": 33,
      "e2e_mean": 8102,
      "e2e_p90": 10533,
      "e2e_p95": 12558,
      "e2e_p99": 15395,
      "tokens_per_second_mean": 338,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 670,
        "accuracy_score": 63.9,
        "hardware": "B200",
        "hardware_count": 8
      },
      "based_on": "DeepSeek R1 family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "minimax/MiniMax-M2",
      "model_name": "MiniMax-M2",
      "hardware": "H200",
      "hardware_count": 8,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 836,
      "ttft_p90": 1194,
      "ttft_p95": 1433,
      "ttft_p99": 1792,
      "itl_mean": 21,
      "itl_p90": 32,
      "itl_p95": 40,
      "itl_p99": 50,
      "e2e_mean": 30209,
      "e2e_p90": 39272,
      "e2e_p95": 46824,
      "e2e_p99": 57397,
      "tokens_per_second_mean": 47,
      "requests_per_second": 0.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 456,
        "accuracy_score": 80.6,
        "hardware": "H200",
        "hardware_count": 8
      },
      "based_on": "Large model patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "minimax/MiniMax-M2",
      "model_name": "MiniMax-M2",
      "hardware": "B200",
      "hardware_count": 8,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 724,
      "ttft_p90": 1035,
      "ttft_p95": 1242,
      "ttft_p99": 1553,
      "itl_mean": 18,
      "itl_p90": 27,
      "itl_p95": 35,
      "itl_p99": 43,
      "e2e_mean": 26181,
      "e2e_p90": 34035,
      "e2e_p95": 40581,
      "e2e_p99": 49744,
      "tokens_per_second_mean": 55,
      "requests_per_second": 0.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 456,
        "accuracy_score": 80.6,
        "hardware": "B200",
        "hardware_count": 8
      },
      "based_on": "Large model patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "mistralai/Magistral-Medium-1.2",
      "model_name": "Magistral Medium 1.2",
      "hardware": "H200",
      "hardware_count": 4,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 118,
      "ttft_p90": 172,
      "ttft_p95": 207,
      "ttft_p99": 254,
      "itl_mean": 16,
      "itl_p90": 24,
      "itl_p95": 30,
      "itl_p99": 38,
      "e2e_mean": 7901,
      "e2e_p90": 10535,
      "e2e_p95": 12511,
      "e2e_p99": 15145,
      "tokens_per_second_mean": 285,
      "requests_per_second": 2.5,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 123,
        "accuracy_score": 63.4,
        "hardware": "H200",
        "hardware_count": 4
      },
      "based_on": "Mistral family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "mistralai/Magistral-Medium-1.2",
      "model_name": "Magistral Medium 1.2",
      "hardware": "B200",
      "hardware_count": 4,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 102,
      "ttft_p90": 149,
      "ttft_p95": 179,
      "ttft_p99": 220,
      "itl_mean": 14,
      "itl_p90": 20,
      "itl_p95": 26,
      "itl_p99": 33,
      "e2e_mean": 6848,
      "e2e_p90": 9130,
      "e2e_p95": 10843,
      "e2e_p99": 13125,
      "tokens_per_second_mean": 324,
      "requests_per_second": 3.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 123,
        "accuracy_score": 63.4,
        "hardware": "B200",
        "hardware_count": 4
      },
      "based_on": "Mistral family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "mistralai/Magistral-Small-1.2",
      "model_name": "Magistral Small 1.2",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 78,
      "ttft_p90": 114,
      "ttft_p95": 134,
      "ttft_p99": 166,
      "itl_mean": 18,
      "itl_p90": 26,
      "itl_p95": 32,
      "itl_p99": 43,
      "e2e_mean": 5742,
      "e2e_p90": 7308,
      "e2e_p95": 8561,
      "e2e_p99": 10440,
      "tokens_per_second_mean": 172,
      "requests_per_second": 1.6,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 24,
        "accuracy_score": 55.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Mistral Small 3.1 patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "mistralai/Magistral-Small-1.2",
      "model_name": "Magistral Small 1.2",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 66,
      "ttft_p90": 97,
      "ttft_p95": 115,
      "ttft_p99": 142,
      "itl_mean": 15,
      "itl_p90": 23,
      "itl_p95": 28,
      "itl_p99": 37,
      "e2e_mean": 4881,
      "e2e_p90": 6212,
      "e2e_p95": 7277,
      "e2e_p99": 8875,
      "tokens_per_second_mean": 229,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 24,
        "accuracy_score": 55.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Mistral Small 3.1 patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "mistralai/Magistral-Small-1.2",
      "model_name": "Magistral Small 1.2",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 50,
      "ttft_p90": 74,
      "ttft_p95": 88,
      "ttft_p99": 109,
      "itl_mean": 11,
      "itl_p90": 17,
      "itl_p95": 21,
      "itl_p99": 28,
      "e2e_mean": 3754,
      "e2e_p90": 4778,
      "e2e_p95": 5597,
      "e2e_p99": 6826,
      "tokens_per_second_mean": 321,
      "requests_per_second": 2.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 24,
        "accuracy_score": 55.0,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "Mistral Small 3.1 patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "nvidia/Llama-Nemotron-Super-49B-v1.5-Reasoning",
      "model_name": "Llama Nemotron Super 49B v1.5 (Reasoning)",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 142,
      "ttft_p90": 207,
      "ttft_p95": 249,
      "ttft_p99": 309,
      "itl_mean": 23,
      "itl_p90": 35,
      "itl_p95": 43,
      "itl_p99": 54,
      "e2e_mean": 10571,
      "e2e_p90": 13874,
      "e2e_p95": 16518,
      "e2e_p99": 19821,
      "tokens_per_second_mean": 183,
      "requests_per_second": 1.8,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 49,
        "accuracy_score": 75.0,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Nemotron 70B patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "nvidia/Llama-Nemotron-Super-49B-v1.5-Reasoning",
      "model_name": "Llama Nemotron Super 49B v1.5 (Reasoning)",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 108,
      "ttft_p90": 159,
      "ttft_p95": 191,
      "ttft_p99": 237,
      "itl_mean": 16,
      "itl_p90": 26,
      "itl_p95": 32,
      "itl_p99": 41,
      "e2e_mean": 8131,
      "e2e_p90": 10672,
      "e2e_p95": 12706,
      "e2e_p99": 15246,
      "tokens_per_second_mean": 256,
      "requests_per_second": 2.6,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 49,
        "accuracy_score": 75.0,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Nemotron 70B patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "upstage/Solar-Pro-2-Reasoning",
      "model_name": "Solar Pro 2 (Reasoning)",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 136,
      "ttft_p90": 201,
      "ttft_p95": 238,
      "ttft_p99": 292,
      "itl_mean": 25,
      "itl_p90": 36,
      "itl_p95": 46,
      "itl_p99": 60,
      "e2e_mean": 11217,
      "e2e_p90": 14275,
      "e2e_p95": 16724,
      "e2e_p99": 20395,
      "tokens_per_second_mean": 127,
      "requests_per_second": 1.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 22,
        "accuracy_score": 65.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "upstage/Solar-Pro-2-Reasoning",
      "model_name": "Solar Pro 2 (Reasoning)",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 116,
      "ttft_p90": 171,
      "ttft_p95": 203,
      "ttft_p99": 249,
      "itl_mean": 22,
      "itl_p90": 31,
      "itl_p95": 39,
      "itl_p99": 51,
      "e2e_mean": 9535,
      "e2e_p90": 12135,
      "e2e_p95": 14216,
      "e2e_p99": 17336,
      "tokens_per_second_mean": 171,
      "requests_per_second": 1.5,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 22,
        "accuracy_score": 65.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "upstage/Solar-Pro-2-Reasoning",
      "model_name": "Solar Pro 2 (Reasoning)",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 89,
      "ttft_p90": 130,
      "ttft_p95": 155,
      "ttft_p99": 191,
      "itl_mean": 16,
      "itl_p90": 24,
      "itl_p95": 29,
      "itl_p99": 39,
      "e2e_mean": 7334,
      "e2e_p90": 9334,
      "e2e_p95": 10934,
      "e2e_p99": 13335,
      "tokens_per_second_mean": 239,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 22,
        "accuracy_score": 65.0,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "deepseek/DeepSeek-R1-Distill-Llama-70B",
      "model_name": "DeepSeek R1 Distill Llama 70B",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 89,
      "ttft_p90": 130,
      "ttft_p95": 156,
      "ttft_p99": 194,
      "itl_mean": 18,
      "itl_p90": 28,
      "itl_p95": 33,
      "itl_p99": 43,
      "e2e_mean": 5996,
      "e2e_p90": 7870,
      "e2e_p95": 9369,
      "e2e_p99": 11242,
      "tokens_per_second_mean": 237,
      "requests_per_second": 2.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 70,
        "accuracy_score": 78.0,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Llama 70B patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "deepseek/DeepSeek-R1-Distill-Llama-70B",
      "model_name": "DeepSeek R1 Distill Llama 70B",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 68,
      "ttft_p90": 100,
      "ttft_p95": 120,
      "ttft_p99": 149,
      "itl_mean": 14,
      "itl_p90": 21,
      "itl_p95": 26,
      "itl_p99": 32,
      "e2e_mean": 4611,
      "e2e_p90": 6052,
      "e2e_p95": 7206,
      "e2e_p99": 8647,
      "tokens_per_second_mean": 331,
      "requests_per_second": 3.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 70,
        "accuracy_score": 78.0,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Llama 70B patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "google/Gemma-3-27B-Instruct",
      "model_name": "Gemma 3 27B Instruct",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 51,
      "ttft_p90": 76,
      "ttft_p95": 90,
      "ttft_p99": 111,
      "itl_mean": 12,
      "itl_p90": 17,
      "itl_p95": 21,
      "itl_p99": 28,
      "e2e_mean": 3830,
      "e2e_p90": 4875,
      "e2e_p95": 5711,
      "e2e_p99": 6965,
      "tokens_per_second_mean": 359,
      "requests_per_second": 3.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 27,
        "accuracy_score": 68.0,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Gemma family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "google/Gemma-3-27B-Instruct",
      "model_name": "Gemma 3 27B Instruct",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 39,
      "ttft_p90": 57,
      "ttft_p95": 69,
      "ttft_p99": 85,
      "itl_mean": 8,
      "itl_p90": 13,
      "itl_p95": 16,
      "itl_p99": 21,
      "e2e_mean": 2945,
      "e2e_p90": 3749,
      "e2e_p95": 4392,
      "e2e_p99": 5357,
      "tokens_per_second_mean": 501,
      "requests_per_second": 4.2,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 27,
        "accuracy_score": 68.0,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Gemma family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "google/Gemma-3-12B-Instruct",
      "model_name": "Gemma 3 12B Instruct",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 80,
      "ttft_p90": 117,
      "ttft_p95": 138,
      "ttft_p99": 171,
      "itl_mean": 19,
      "itl_p90": 27,
      "itl_p95": 33,
      "itl_p99": 44,
      "e2e_mean": 5887,
      "e2e_p90": 7493,
      "e2e_p95": 8778,
      "e2e_p99": 10705,
      "tokens_per_second_mean": 170,
      "requests_per_second": 1.6,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 12,
        "accuracy_score": 58.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Gemma family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "google/Gemma-3-12B-Instruct",
      "model_name": "Gemma 3 12B Instruct",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 68,
      "ttft_p90": 100,
      "ttft_p95": 118,
      "ttft_p99": 145,
      "itl_mean": 16,
      "itl_p90": 23,
      "itl_p95": 29,
      "itl_p99": 38,
      "e2e_mean": 5005,
      "e2e_p90": 6370,
      "e2e_p95": 7462,
      "e2e_p99": 9100,
      "tokens_per_second_mean": 227,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 12,
        "accuracy_score": 58.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Gemma family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "google/Gemma-3-12B-Instruct",
      "model_name": "Gemma 3 12B Instruct",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 51,
      "ttft_p90": 76,
      "ttft_p95": 91,
      "ttft_p99": 111,
      "itl_mean": 11,
      "itl_p90": 18,
      "itl_p95": 21,
      "itl_p99": 29,
      "e2e_mean": 3849,
      "e2e_p90": 4899,
      "e2e_p95": 5739,
      "e2e_p99": 6999,
      "tokens_per_second_mean": 319,
      "requests_per_second": 2.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 12,
        "accuracy_score": 58.0,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "Gemma family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "model_name": "Llama 3.1 Instruct 405B",
      "hardware": "H200",
      "hardware_count": 8,
      "prompt_tokens": 4096,
      "output_tokens": 512,
      "ttft_mean": 444,
      "ttft_p90": 634,
      "ttft_p95": 762,
      "ttft_p99": 952,
      "itl_mean": 15,
      "itl_p90": 24,
      "itl_p95": 29,
      "itl_p99": 36,
      "e2e_mean": 17372,
      "e2e_p90": 22583,
      "e2e_p95": 26926,
      "e2e_p99": 33007,
      "tokens_per_second_mean": 111,
      "requests_per_second": 1.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 405,
        "accuracy_score": 82.0,
        "hardware": "H200",
        "hardware_count": 8
      },
      "based_on": "Llama family patterns",
      "best_use_case": "summarization_short"
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "model_name": "Llama 3.1 Instruct 405B",
      "hardware": "B200",
      "hardware_count": 8,
      "prompt_tokens": 4096,
      "output_tokens": 512,
      "ttft_mean": 385,
      "ttft_p90": 550,
      "ttft_p95": 660,
      "ttft_p99": 825,
      "itl_mean": 13,
      "itl_p90": 20,
      "itl_p95": 25,
      "itl_p99": 32,
      "e2e_mean": 15055,
      "e2e_p90": 19572,
      "e2e_p95": 23336,
      "e2e_p99": 28606,
      "tokens_per_second_mean": 128,
      "requests_per_second": 1.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 405,
        "accuracy_score": 82.0,
        "hardware": "B200",
        "hardware_count": 8
      },
      "based_on": "Llama family patterns",
      "best_use_case": "summarization_short"
    },
    {
      "model_id": "mistralai/Mistral-Medium-3.1",
      "model_name": "Mistral Medium 3.1",
      "hardware": "H200",
      "hardware_count": 4,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 76,
      "ttft_p90": 111,
      "ttft_p95": 134,
      "ttft_p99": 165,
      "itl_mean": 13,
      "itl_p90": 20,
      "itl_p95": 25,
      "itl_p99": 31,
      "e2e_mean": 4615,
      "e2e_p90": 6153,
      "e2e_p95": 7307,
      "e2e_p99": 8846,
      "tokens_per_second_mean": 369,
      "requests_per_second": 3.2,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 123,
        "accuracy_score": 70.0,
        "hardware": "H200",
        "hardware_count": 4
      },
      "based_on": "Mistral family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "mistralai/Mistral-Medium-3.1",
      "model_name": "Mistral Medium 3.1",
      "hardware": "B200",
      "hardware_count": 4,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 66,
      "ttft_p90": 96,
      "ttft_p95": 116,
      "ttft_p99": 143,
      "itl_mean": 11,
      "itl_p90": 17,
      "itl_p95": 21,
      "itl_p99": 27,
      "e2e_mean": 4000,
      "e2e_p90": 5333,
      "e2e_p95": 6333,
      "e2e_p99": 7666,
      "tokens_per_second_mean": 422,
      "requests_per_second": 3.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 123,
        "accuracy_score": 70.0,
        "hardware": "B200",
        "hardware_count": 4
      },
      "based_on": "Mistral family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "mistralai/Mistral-Small-3.2",
      "model_name": "Mistral Small 3.2",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 81,
      "ttft_p90": 119,
      "ttft_p95": 140,
      "ttft_p99": 173,
      "itl_mean": 19,
      "itl_p90": 27,
      "itl_p95": 34,
      "itl_p99": 45,
      "e2e_mean": 5984,
      "e2e_p90": 7617,
      "e2e_p95": 8923,
      "e2e_p99": 10881,
      "tokens_per_second_mean": 169,
      "requests_per_second": 1.5,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 24,
        "accuracy_score": 60.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Mistral Small 3.1 patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "mistralai/Mistral-Small-3.2",
      "model_name": "Mistral Small 3.2",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 69,
      "ttft_p90": 101,
      "ttft_p95": 120,
      "ttft_p99": 148,
      "itl_mean": 16,
      "itl_p90": 24,
      "itl_p95": 29,
      "itl_p99": 38,
      "e2e_mean": 5087,
      "e2e_p90": 6475,
      "e2e_p95": 7585,
      "e2e_p99": 9250,
      "tokens_per_second_mean": 226,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 24,
        "accuracy_score": 60.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Mistral Small 3.1 patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "mistralai/Mistral-Small-3.2",
      "model_name": "Mistral Small 3.2",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 52,
      "ttft_p90": 77,
      "ttft_p95": 92,
      "ttft_p99": 113,
      "itl_mean": 12,
      "itl_p90": 18,
      "itl_p95": 22,
      "itl_p99": 29,
      "e2e_mean": 3912,
      "e2e_p90": 4980,
      "e2e_p95": 5833,
      "e2e_p99": 7115,
      "tokens_per_second_mean": 317,
      "requests_per_second": 2.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 24,
        "accuracy_score": 60.0,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "Mistral Small 3.1 patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "deepseek/DeepSeek-R1-0528-Qwen3-8B",
      "model_name": "DeepSeek R1 0528 Qwen3 8B",
      "hardware": "L4",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 99,
      "ttft_p90": 143,
      "ttft_p95": 173,
      "ttft_p99": 210,
      "itl_mean": 26,
      "itl_p90": 39,
      "itl_p95": 48,
      "itl_p99": 62,
      "e2e_mean": 7765,
      "e2e_p90": 9984,
      "e2e_p95": 11537,
      "e2e_p99": 13756,
      "tokens_per_second_mean": 100,
      "requests_per_second": 0.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 8,
        "accuracy_score": 55.0,
        "hardware": "L4",
        "hardware_count": 1
      },
      "based_on": "Qwen3-8B patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "deepseek/DeepSeek-R1-0528-Qwen3-8B",
      "model_name": "DeepSeek R1 0528 Qwen3 8B",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 46,
      "ttft_p90": 67,
      "ttft_p95": 80,
      "ttft_p99": 98,
      "itl_mean": 12,
      "itl_p90": 18,
      "itl_p95": 22,
      "itl_p99": 28,
      "e2e_mean": 3653,
      "e2e_p90": 4698,
      "e2e_p95": 5428,
      "e2e_p99": 6473,
      "tokens_per_second_mean": 250,
      "requests_per_second": 2.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 8,
        "accuracy_score": 55.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Qwen3-8B patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "deepseek/DeepSeek-R1-0528-Qwen3-8B",
      "model_name": "DeepSeek R1 0528 Qwen3 8B",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 39,
      "ttft_p90": 57,
      "ttft_p95": 69,
      "ttft_p99": 84,
      "itl_mean": 10,
      "itl_p90": 15,
      "itl_p95": 19,
      "itl_p99": 24,
      "e2e_mean": 3106,
      "e2e_p90": 3993,
      "e2e_p95": 4615,
      "e2e_p99": 5502,
      "tokens_per_second_mean": 334,
      "requests_per_second": 3.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 8,
        "accuracy_score": 55.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Qwen3-8B patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "qwen/Qwen3-235B-A22B-Thinking",
      "model_name": "Qwen3 235B A22B (Thinking)",
      "hardware": "H200",
      "hardware_count": 8,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 433,
      "ttft_p90": 628,
      "ttft_p95": 758,
      "ttft_p99": 932,
      "itl_mean": 13,
      "itl_p90": 20,
      "itl_p95": 25,
      "itl_p99": 32,
      "e2e_mean": 16450,
      "e2e_p90": 21934,
      "e2e_p95": 26046,
      "e2e_p99": 31530,
      "tokens_per_second_mean": 81,
      "requests_per_second": 0.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 235,
        "accuracy_score": 67.3,
        "hardware": "H200",
        "hardware_count": 8
      },
      "based_on": "Qwen family patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "qwen/Qwen3-235B-A22B-Thinking",
      "model_name": "Qwen3 235B A22B (Thinking)",
      "hardware": "B200",
      "hardware_count": 8,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 375,
      "ttft_p90": 545,
      "ttft_p95": 657,
      "ttft_p99": 807,
      "itl_mean": 11,
      "itl_p90": 17,
      "itl_p95": 21,
      "itl_p99": 28,
      "e2e_mean": 14257,
      "e2e_p90": 19009,
      "e2e_p95": 22574,
      "e2e_p99": 27326,
      "tokens_per_second_mean": 94,
      "requests_per_second": 0.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 235,
        "accuracy_score": 67.3,
        "hardware": "B200",
        "hardware_count": 8
      },
      "based_on": "Qwen family patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "microsoft/Phi-4-Mini-Instruct",
      "model_name": "Phi-4 Mini Instruct",
      "hardware": "L4",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 96,
      "ttft_p90": 140,
      "ttft_p95": 168,
      "ttft_p99": 205,
      "itl_mean": 25,
      "itl_p90": 38,
      "itl_p95": 47,
      "itl_p99": 60,
      "e2e_mean": 7568,
      "e2e_p90": 9731,
      "e2e_p95": 11245,
      "e2e_p99": 13407,
      "tokens_per_second_mean": 101,
      "requests_per_second": 0.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 3.8,
        "accuracy_score": 52.0,
        "hardware": "L4",
        "hardware_count": 1
      },
      "based_on": "Phi-4 patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "microsoft/Phi-4-Mini-Instruct",
      "model_name": "Phi-4 Mini Instruct",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 44,
      "ttft_p90": 65,
      "ttft_p95": 78,
      "ttft_p99": 96,
      "itl_mean": 12,
      "itl_p90": 18,
      "itl_p95": 21,
      "itl_p99": 27,
      "e2e_mean": 3561,
      "e2e_p90": 4579,
      "e2e_p95": 5291,
      "e2e_p99": 6309,
      "tokens_per_second_mean": 252,
      "requests_per_second": 2.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 3.8,
        "accuracy_score": 52.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Phi-4 patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "microsoft/Phi-4-Mini-Instruct",
      "model_name": "Phi-4 Mini Instruct",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 38,
      "ttft_p90": 56,
      "ttft_p95": 67,
      "ttft_p99": 82,
      "itl_mean": 10,
      "itl_p90": 15,
      "itl_p95": 19,
      "itl_p99": 24,
      "e2e_mean": 3027,
      "e2e_p90": 3892,
      "e2e_p95": 4498,
      "e2e_p99": 5363,
      "tokens_per_second_mean": 337,
      "requests_per_second": 3.2,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 3.8,
        "accuracy_score": 52.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Phi-4 patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "nvidia/Nemotron-Nano-9B-V2-Reasoning",
      "model_name": "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 47,
      "ttft_p90": 69,
      "ttft_p95": 82,
      "ttft_p99": 101,
      "itl_mean": 12,
      "itl_p90": 19,
      "itl_p95": 22,
      "itl_p99": 29,
      "e2e_mean": 3746,
      "e2e_p90": 4817,
      "e2e_p95": 5566,
      "e2e_p99": 6637,
      "tokens_per_second_mean": 248,
      "requests_per_second": 2.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 9,
        "accuracy_score": 58.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Nemotron Nano patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "nvidia/Nemotron-Nano-9B-V2-Reasoning",
      "model_name": "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 40,
      "ttft_p90": 59,
      "ttft_p95": 70,
      "ttft_p99": 86,
      "itl_mean": 10,
      "itl_p90": 16,
      "itl_p95": 20,
      "itl_p99": 25,
      "e2e_mean": 3185,
      "e2e_p90": 4095,
      "e2e_p95": 4732,
      "e2e_p99": 5642,
      "tokens_per_second_mean": 331,
      "requests_per_second": 3.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 9,
        "accuracy_score": 58.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Nemotron Nano patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "nvidia/Nemotron-Nano-9B-V2-Reasoning",
      "model_name": "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 30,
      "ttft_p90": 45,
      "ttft_p95": 54,
      "ttft_p99": 66,
      "itl_mean": 8,
      "itl_p90": 11,
      "itl_p95": 14,
      "itl_p99": 19,
      "e2e_mean": 2449,
      "e2e_p90": 3149,
      "e2e_p95": 3640,
      "e2e_p99": 4339,
      "tokens_per_second_mean": 464,
      "requests_per_second": 4.4,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 9,
        "accuracy_score": 58.0,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "Nemotron Nano patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "nvidia/Llama-3.3-Nemotron-Super-49B-v1-Reasoning",
      "model_name": "Llama 3.3 Nemotron Super 49B v1 (Reasoning)",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 140,
      "ttft_p90": 206,
      "ttft_p95": 248,
      "ttft_p99": 306,
      "itl_mean": 22,
      "itl_p90": 35,
      "itl_p95": 42,
      "itl_p99": 54,
      "e2e_mean": 10494,
      "e2e_p90": 13774,
      "e2e_p95": 16398,
      "e2e_p99": 19678,
      "tokens_per_second_mean": 183,
      "requests_per_second": 1.8,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 49,
        "accuracy_score": 74.0,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Nemotron patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "nvidia/Llama-3.3-Nemotron-Super-49B-v1-Reasoning",
      "model_name": "Llama 3.3 Nemotron Super 49B v1 (Reasoning)",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 108,
      "ttft_p90": 158,
      "ttft_p95": 190,
      "ttft_p99": 235,
      "itl_mean": 16,
      "itl_p90": 26,
      "itl_p95": 32,
      "itl_p99": 41,
      "e2e_mean": 8072,
      "e2e_p90": 10595,
      "e2e_p95": 12614,
      "e2e_p99": 15136,
      "tokens_per_second_mean": 258,
      "requests_per_second": 2.6,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 49,
        "accuracy_score": 74.0,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Nemotron patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "upstage/Solar-Pro-2-Non-reasoning",
      "model_name": "Solar Pro 2 (Non-reasoning)",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 80,
      "ttft_p90": 117,
      "ttft_p95": 138,
      "ttft_p99": 171,
      "itl_mean": 19,
      "itl_p90": 27,
      "itl_p95": 33,
      "itl_p99": 44,
      "e2e_mean": 5887,
      "e2e_p90": 7493,
      "e2e_p95": 8778,
      "e2e_p99": 10705,
      "tokens_per_second_mean": 170,
      "requests_per_second": 1.6,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 22,
        "accuracy_score": 58.0,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "upstage/Solar-Pro-2-Non-reasoning",
      "model_name": "Solar Pro 2 (Non-reasoning)",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 68,
      "ttft_p90": 100,
      "ttft_p95": 118,
      "ttft_p99": 145,
      "itl_mean": 16,
      "itl_p90": 23,
      "itl_p95": 29,
      "itl_p99": 38,
      "e2e_mean": 5005,
      "e2e_p90": 6370,
      "e2e_p95": 7462,
      "e2e_p99": 9100,
      "tokens_per_second_mean": 227,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 22,
        "accuracy_score": 58.0,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "upstage/Solar-Pro-2-Non-reasoning",
      "model_name": "Solar Pro 2 (Non-reasoning)",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 51,
      "ttft_p90": 76,
      "ttft_p95": 91,
      "ttft_p99": 111,
      "itl_mean": 11,
      "itl_p90": 18,
      "itl_p95": 21,
      "itl_p99": 29,
      "e2e_mean": 3849,
      "e2e_p90": 4899,
      "e2e_p95": 5739,
      "e2e_p99": 6999,
      "tokens_per_second_mean": 319,
      "requests_per_second": 2.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 22,
        "accuracy_score": 58.0,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "deepseek/DeepSeek-V3.2-Exp-Non-reasoning",
      "model_name": "DeepSeek V3.2 Exp (Non-reasoning)",
      "hardware": "H200",
      "hardware_count": 8,
      "prompt_tokens": 4096,
      "output_tokens": 512,
      "ttft_mean": 361,
      "ttft_p90": 516,
      "ttft_p95": 620,
      "ttft_p99": 775,
      "itl_mean": 13,
      "itl_p90": 19,
      "itl_p95": 24,
      "itl_p99": 30,
      "e2e_mean": 14144,
      "e2e_p90": 18388,
      "e2e_p95": 21924,
      "e2e_p99": 26875,
      "tokens_per_second_mean": 124,
      "requests_per_second": 1.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 670,
        "accuracy_score": 55.0,
        "hardware": "H200",
        "hardware_count": 8
      },
      "based_on": "DeepSeek patterns",
      "best_use_case": "summarization_short"
    },
    {
      "model_id": "deepseek/DeepSeek-V3.2-Exp-Non-reasoning",
      "model_name": "DeepSeek V3.2 Exp (Non-reasoning)",
      "hardware": "B200",
      "hardware_count": 8,
      "prompt_tokens": 4096,
      "output_tokens": 512,
      "ttft_mean": 313,
      "ttft_p90": 447,
      "ttft_p95": 537,
      "ttft_p99": 672,
      "itl_mean": 10,
      "itl_p90": 16,
      "itl_p95": 20,
      "itl_p99": 26,
      "e2e_mean": 12258,
      "e2e_p90": 15936,
      "e2e_p95": 19001,
      "e2e_p99": 23291,
      "tokens_per_second_mean": 141,
      "requests_per_second": 1.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 670,
        "accuracy_score": 55.0,
        "hardware": "B200",
        "hardware_count": 8
      },
      "based_on": "DeepSeek patterns",
      "best_use_case": "summarization_short"
    },
    {
      "model_id": "moonshot/Kimi-K2-Thinking",
      "model_name": "Kimi K2 Thinking",
      "hardware": "H200",
      "hardware_count": 4,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 147,
      "ttft_p90": 214,
      "ttft_p95": 258,
      "ttft_p99": 317,
      "itl_mean": 20,
      "itl_p90": 30,
      "itl_p95": 37,
      "itl_p99": 48,
      "e2e_mean": 9852,
      "e2e_p90": 13137,
      "e2e_p95": 15601,
      "e2e_p99": 18885,
      "tokens_per_second_mean": 258,
      "requests_per_second": 2.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 200,
        "accuracy_score": 94.7,
        "hardware": "H200",
        "hardware_count": 4
      },
      "based_on": "Kimi K2 Instruct patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "moonshot/Kimi-K2-Thinking",
      "model_name": "Kimi K2 Thinking",
      "hardware": "B200",
      "hardware_count": 4,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 128,
      "ttft_p90": 186,
      "ttft_p95": 224,
      "ttft_p99": 275,
      "itl_mean": 17,
      "itl_p90": 26,
      "itl_p95": 33,
      "itl_p99": 41,
      "e2e_mean": 8539,
      "e2e_p90": 11386,
      "e2e_p95": 13521,
      "e2e_p99": 16367,
      "tokens_per_second_mean": 295,
      "requests_per_second": 2.8,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 200,
        "accuracy_score": 94.7,
        "hardware": "B200",
        "hardware_count": 4
      },
      "based_on": "Kimi K2 Instruct patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "inclusionai/Ring-1T",
      "model_name": "Ring-1T",
      "hardware": "H200",
      "hardware_count": 8,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 886,
      "ttft_p90": 1266,
      "ttft_p95": 1520,
      "ttft_p99": 1900,
      "itl_mean": 22,
      "itl_p90": 34,
      "itl_p95": 42,
      "itl_p99": 53,
      "e2e_mean": 32035,
      "e2e_p90": 41645,
      "e2e_p95": 49654,
      "e2e_p99": 60867,
      "tokens_per_second_mean": 47,
      "requests_per_second": 0.3,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 1000,
        "accuracy_score": 89.3,
        "hardware": "H200",
        "hardware_count": 8
      },
      "based_on": "Large model patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "inclusionai/Ring-1T",
      "model_name": "Ring-1T",
      "hardware": "B200",
      "hardware_count": 8,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 768,
      "ttft_p90": 1097,
      "ttft_p95": 1317,
      "ttft_p99": 1647,
      "itl_mean": 20,
      "itl_p90": 29,
      "itl_p95": 37,
      "itl_p99": 45,
      "e2e_mean": 27763,
      "e2e_p90": 36092,
      "e2e_p95": 43033,
      "e2e_p99": 52751,
      "tokens_per_second_mean": 55,
      "requests_per_second": 0.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 1000,
        "accuracy_score": 89.3,
        "hardware": "B200",
        "hardware_count": 8
      },
      "based_on": "Large model patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "zai/GLM-4.5-Reasoning",
      "model_name": "GLM-4.5 (Reasoning)",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 154,
      "ttft_p90": 226,
      "ttft_p95": 272,
      "ttft_p99": 336,
      "itl_mean": 25,
      "itl_p90": 38,
      "itl_p95": 46,
      "itl_p99": 59,
      "e2e_mean": 11510,
      "e2e_p90": 15108,
      "e2e_p95": 17986,
      "e2e_p99": 21583,
      "tokens_per_second_mean": 177,
      "requests_per_second": 1.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 60,
        "accuracy_score": 87.3,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "GLM family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "zai/GLM-4.5-Reasoning",
      "model_name": "GLM-4.5 (Reasoning)",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 118,
      "ttft_p90": 173,
      "ttft_p95": 208,
      "ttft_p99": 258,
      "itl_mean": 19,
      "itl_p90": 28,
      "itl_p95": 35,
      "itl_p99": 45,
      "e2e_mean": 8854,
      "e2e_p90": 11621,
      "e2e_p95": 13835,
      "e2e_p99": 16602,
      "tokens_per_second_mean": 246,
      "requests_per_second": 2.4,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 60,
        "accuracy_score": 87.3,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "GLM family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "servicenow/Apriel-v1.5-15B-Thinker",
      "model_name": "Apriel-v1.5-15B-Thinker",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 99,
      "ttft_p90": 145,
      "ttft_p95": 171,
      "ttft_p99": 212,
      "itl_mean": 23,
      "itl_p90": 33,
      "itl_p95": 41,
      "itl_p99": 55,
      "e2e_mean": 7319,
      "e2e_p90": 9315,
      "e2e_p95": 10913,
      "e2e_p99": 13308,
      "tokens_per_second_mean": 156,
      "requests_per_second": 1.4,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 15,
        "accuracy_score": 87.5,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "servicenow/Apriel-v1.5-15B-Thinker",
      "model_name": "Apriel-v1.5-15B-Thinker",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 84,
      "ttft_p90": 124,
      "ttft_p95": 147,
      "ttft_p99": 181,
      "itl_mean": 20,
      "itl_p90": 29,
      "itl_p95": 36,
      "itl_p99": 47,
      "e2e_mean": 6221,
      "e2e_p90": 7918,
      "e2e_p95": 9276,
      "e2e_p99": 11312,
      "tokens_per_second_mean": 208,
      "requests_per_second": 1.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 15,
        "accuracy_score": 87.5,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "servicenow/Apriel-v1.5-15B-Thinker",
      "model_name": "Apriel-v1.5-15B-Thinker",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 64,
      "ttft_p90": 95,
      "ttft_p95": 113,
      "ttft_p99": 139,
      "itl_mean": 14,
      "itl_p90": 22,
      "itl_p95": 27,
      "itl_p99": 36,
      "e2e_mean": 4785,
      "e2e_p90": 6090,
      "e2e_p95": 7134,
      "e2e_p99": 8701,
      "tokens_per_second_mean": 291,
      "requests_per_second": 2.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 15,
        "accuracy_score": 87.5,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "lgai/EXAONE-4.0-32B-Reasoning",
      "model_name": "EXAONE 4.0 32B (Reasoning)",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 151,
      "ttft_p90": 222,
      "ttft_p95": 266,
      "ttft_p99": 330,
      "itl_mean": 24,
      "itl_p90": 38,
      "itl_p95": 45,
      "itl_p99": 58,
      "e2e_mean": 11281,
      "e2e_p90": 14807,
      "e2e_p95": 17628,
      "e2e_p99": 21153,
      "tokens_per_second_mean": 178,
      "requests_per_second": 1.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 32,
        "accuracy_score": 84.3,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "lgai/EXAONE-4.0-32B-Reasoning",
      "model_name": "EXAONE 4.0 32B (Reasoning)",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 115,
      "ttft_p90": 170,
      "ttft_p95": 205,
      "ttft_p99": 253,
      "itl_mean": 18,
      "itl_p90": 28,
      "itl_p95": 34,
      "itl_p99": 44,
      "e2e_mean": 8677,
      "e2e_p90": 11390,
      "e2e_p95": 13560,
      "e2e_p99": 16271,
      "tokens_per_second_mean": 250,
      "requests_per_second": 2.4,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 32,
        "accuracy_score": 84.3,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Medium model patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "minimax/MiniMax-M1-80k",
      "model_name": "MiniMax M1 80k",
      "hardware": "H200",
      "hardware_count": 4,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 416,
      "ttft_p90": 607,
      "ttft_p95": 729,
      "ttft_p99": 903,
      "itl_mean": 15,
      "itl_p90": 23,
      "itl_p95": 29,
      "itl_p99": 36,
      "e2e_mean": 17575,
      "e2e_p90": 23068,
      "e2e_p95": 27462,
      "e2e_p99": 32954,
      "tokens_per_second_mean": 73,
      "requests_per_second": 0.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 80,
        "accuracy_score": 84.7,
        "hardware": "H200",
        "hardware_count": 4
      },
      "based_on": "MiniMax patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "minimax/MiniMax-M1-80k",
      "model_name": "MiniMax M1 80k",
      "hardware": "B200",
      "hardware_count": 4,
      "prompt_tokens": 10240,
      "output_tokens": 1536,
      "ttft_mean": 361,
      "ttft_p90": 526,
      "ttft_p95": 632,
      "ttft_p99": 782,
      "itl_mean": 13,
      "itl_p90": 21,
      "itl_p95": 25,
      "itl_p99": 32,
      "e2e_mean": 15232,
      "e2e_p90": 19992,
      "e2e_p95": 23800,
      "e2e_p99": 28560,
      "tokens_per_second_mean": 87,
      "requests_per_second": 0.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 80,
        "accuracy_score": 84.7,
        "hardware": "B200",
        "hardware_count": 4
      },
      "based_on": "MiniMax patterns",
      "best_use_case": "research_legal_analysis"
    },
    {
      "model_id": "bytedance/Doubao-Seed-Code",
      "model_name": "Doubao Seed Code",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 56,
      "ttft_p90": 82,
      "ttft_p95": 98,
      "ttft_p99": 120,
      "itl_mean": 13,
      "itl_p90": 19,
      "itl_p95": 24,
      "itl_p99": 31,
      "e2e_mean": 4159,
      "e2e_p90": 5294,
      "e2e_p95": 6202,
      "e2e_p99": 7563,
      "tokens_per_second_mean": 346,
      "requests_per_second": 2.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 30,
        "accuracy_score": 79.3,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Code model patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "bytedance/Doubao-Seed-Code",
      "model_name": "Doubao Seed Code",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 42,
      "ttft_p90": 62,
      "ttft_p95": 74,
      "ttft_p99": 92,
      "itl_mean": 9,
      "itl_p90": 14,
      "itl_p95": 17,
      "itl_p99": 24,
      "e2e_mean": 3199,
      "e2e_p90": 4072,
      "e2e_p95": 4770,
      "e2e_p99": 5818,
      "tokens_per_second_mean": 485,
      "requests_per_second": 4.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 30,
        "accuracy_score": 79.3,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Code model patterns",
      "best_use_case": "code_completion"
    },
    {
      "model_id": "bytedance/Seed-OSS-36B-Instruct",
      "model_name": "Seed-OSS-36B-Instruct",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 94,
      "ttft_p90": 137,
      "ttft_p95": 164,
      "ttft_p99": 203,
      "itl_mean": 19,
      "itl_p90": 29,
      "itl_p95": 36,
      "itl_p99": 45,
      "e2e_mean": 6280,
      "e2e_p90": 8242,
      "e2e_p95": 9813,
      "e2e_p99": 11775,
      "tokens_per_second_mean": 232,
      "requests_per_second": 2.1,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 36,
        "accuracy_score": 84.7,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Medium model patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "bytedance/Seed-OSS-36B-Instruct",
      "model_name": "Seed-OSS-36B-Instruct",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 72,
      "ttft_p90": 104,
      "ttft_p95": 125,
      "ttft_p99": 156,
      "itl_mean": 14,
      "itl_p90": 22,
      "itl_p95": 26,
      "itl_p99": 33,
      "e2e_mean": 4830,
      "e2e_p90": 6339,
      "e2e_p95": 7548,
      "e2e_p99": 9058,
      "tokens_per_second_mean": 324,
      "requests_per_second": 3.0,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 36,
        "accuracy_score": 84.7,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Medium model patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "alibaba/Qwen3-32B-Reasoning",
      "model_name": "Qwen3 32B (Reasoning)",
      "hardware": "H100",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 147,
      "ttft_p90": 216,
      "ttft_p95": 260,
      "ttft_p99": 321,
      "itl_mean": 24,
      "itl_p90": 36,
      "itl_p95": 44,
      "itl_p99": 57,
      "e2e_mean": 11006,
      "e2e_p90": 14446,
      "e2e_p95": 17198,
      "e2e_p99": 20638,
      "tokens_per_second_mean": 180,
      "requests_per_second": 1.8,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 32,
        "accuracy_score": 80.7,
        "hardware": "H100",
        "hardware_count": 2
      },
      "based_on": "Qwen family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "alibaba/Qwen3-32B-Reasoning",
      "model_name": "Qwen3 32B (Reasoning)",
      "hardware": "H200",
      "hardware_count": 2,
      "prompt_tokens": 1024,
      "output_tokens": 1024,
      "ttft_mean": 113,
      "ttft_p90": 166,
      "ttft_p95": 200,
      "ttft_p99": 247,
      "itl_mean": 17,
      "itl_p90": 27,
      "itl_p95": 33,
      "itl_p99": 43,
      "e2e_mean": 8466,
      "e2e_p90": 11112,
      "e2e_p95": 13229,
      "e2e_p99": 15874,
      "tokens_per_second_mean": 251,
      "requests_per_second": 2.4,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 32,
        "accuracy_score": 80.7,
        "hardware": "H200",
        "hardware_count": 2
      },
      "based_on": "Qwen family patterns",
      "best_use_case": "code_generation_detailed"
    },
    {
      "model_id": "zai/GLM-4.5-Air",
      "model_name": "GLM-4.5-Air",
      "hardware": "A100-80",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 95,
      "ttft_p90": 139,
      "ttft_p95": 164,
      "ttft_p99": 203,
      "itl_mean": 22,
      "itl_p90": 32,
      "itl_p95": 39,
      "itl_p99": 52,
      "e2e_mean": 6989,
      "e2e_p90": 8895,
      "e2e_p95": 10421,
      "e2e_p99": 12708,
      "tokens_per_second_mean": 159,
      "requests_per_second": 1.5,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 20,
        "accuracy_score": 80.7,
        "hardware": "A100-80",
        "hardware_count": 1
      },
      "based_on": "GLM family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "zai/GLM-4.5-Air",
      "model_name": "GLM-4.5-Air",
      "hardware": "H100",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 81,
      "ttft_p90": 118,
      "ttft_p95": 140,
      "ttft_p99": 172,
      "itl_mean": 19,
      "itl_p90": 28,
      "itl_p95": 34,
      "itl_p99": 45,
      "e2e_mean": 5941,
      "e2e_p90": 7561,
      "e2e_p95": 8858,
      "e2e_p99": 10802,
      "tokens_per_second_mean": 212,
      "requests_per_second": 1.9,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 20,
        "accuracy_score": 80.7,
        "hardware": "H100",
        "hardware_count": 1
      },
      "based_on": "GLM family patterns",
      "best_use_case": "chatbot_conversational"
    },
    {
      "model_id": "zai/GLM-4.5-Air",
      "model_name": "GLM-4.5-Air",
      "hardware": "H200",
      "hardware_count": 1,
      "prompt_tokens": 512,
      "output_tokens": 256,
      "ttft_mean": 61,
      "ttft_p90": 90,
      "ttft_p95": 108,
      "ttft_p99": 132,
      "itl_mean": 14,
      "itl_p90": 21,
      "itl_p95": 25,
      "itl_p99": 34,
      "e2e_mean": 4569,
      "e2e_p90": 5816,
      "e2e_p95": 6813,
      "e2e_p99": 8309,
      "tokens_per_second_mean": 298,
      "requests_per_second": 2.7,
      "estimated": true,
      "estimation_method": "size_hardware_accuracy_interpolation",
      "estimation_confidence": 0.8,
      "estimation_factors": {
        "size_params_b": 20,
        "accuracy_score": 80.7,
        "hardware": "H200",
        "hardware_count": 1
      },
      "based_on": "GLM family patterns",
      "best_use_case": "chatbot_conversational"
    }
  ]
}